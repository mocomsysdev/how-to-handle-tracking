개발할 시스템의 간략한 요구사항을 정리해 보면 다음과 같습니다.


[ 요구 사항 ]
``````
1) 하나의 거래는 복수의 프로세스 처리로 이루어진다. 예) 송신->허브->수신 
2) 거래를 처리하는 각 단계의 프로세스는 개별적인 트래킹 로그를 발생시킨다.
3) 로그처리 시스템은 각 단계별 프로세스의 로그를 수집하여 특정 테이블에 적재한다.
4) 송신 허브 수신 각 단계별로 수집된 로그에서 거래의 최종 처리 상태를 확인할 수 있도록 요약 정보를 생성하여 적재한다.
``````

위의 요구사항을 그림으로 표현하면 다음과 같습니다.

![거래 단계별 트래킹](./images/fig01.요구사항.png)

트래킹 메시지 내용에 대해서는 아직 언급하지 않겠습니다. 트래킹 메시지 발생 구조에 집중하여 시스템 설계를 진행해 봅시다.

우선 새롭계 설계할 시스템의 걔선 포인트를 찾기위해 기존 처리 방식을 간략히 설명하고자 합니다.

아래 그림에서와 같이 기존 처리 방식은 시스템 차원에서 접근했다기 보다는 트래킹 로그를 처리하는 기능적 측면에서만 고려하고 있어서 양적 측면과 기능적 측면 모두에서 확장을 고려하기엔 부족한 모습입니다.

[기존 시스템 구성 그림]

기존 로그처리 방식에서 개선점을 찾아 본다면 다음과 같이 정리해 볼 수 있을 것 같습니다.

```
    - H/W 확장에 따른 시스템(로그처리 S/W) 확장가능
    - 다양한 로그 채널 허용 
    - 대량 데이터 처리
    - 트래킹 로그 활용
```

아래는 개선점을 고려한 초기 아키텍처 모습입니다.

![새로운 아키텍처](./images/fig03.NEW아키텍처.png)

위 아키텍처에서는 구체적으로 다음 포인트를 목표로 하고 있습니다.

```
    1) 다양한 채널로 로그 수집
    2) 다양한 형식의 로그 수집
    3) 동시처리 및 수평확장 스트림데이터 파티셔닝 지원
    4) 로그 저장 레파지토리의 다양성 보장
    5) 알림 등 로그 활용성 확대
```

1) 다양한 채널로 로그 수집 

    기존에 IBM Websphere 의 큐를 통해 EAI 인터페이스를 구축해 오던 환경에서 자연스럽게 로그 수집 또한 큐를 통해 로그 이벤트를 쌓고 처리하는 방식이었다면,
    새로운 아키텍처에서는 기존의 큐를 포함 REST 서비스 프로바이더 및 파일 등 다양한 형태의 입력 로그를 처리할 수 있는 입력 채널 다변화를 지원할 수 있으면 좋겠습니다.

2) 다양한 형식의 로그 수집

    입력 채널의 방식에 따라 수집되는 로그의 형식이 달라짐에 따라 로그 시스템 내부에서
    다루어야 하는 형식도 다양해지므로 로그시스템 내부에는 슈퍼셋 형태의 표준 형식을 정하고 채널별로 다양한 형식을 수집시점에 표준로그로 파싱하면 좋겠습니다.

3) 동시처리 및 수평확장 스트림데이터 파티셔닝 지원

4) 로그 저장 레파지토리의 다양성 보장

5) 알림 등 로그 활용성 확대
